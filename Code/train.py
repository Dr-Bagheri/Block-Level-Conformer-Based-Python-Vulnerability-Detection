import keras_metrics as km
import numpy as np
from keras.callbacks import ModelCheckpoint
from keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Input, concatenate, \
    Dropout, Reshape
from tensorflow.keras.optimizers import Adam
from keras import backend as K
from keras import initializers
from keras.layers import Layer
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
class SinusoidalPositionEmbedding(Layer):


    def __init__(
            self, output_dim, merge_mode='add', custom_position_ids=False, **kwargs
    ):
        super(SinusoidalPositionEmbedding, self).__init__(**kwargs)
        self.output_dim = output_dim
        self.merge_mode = merge_mode
        self.custom_position_ids = custom_position_ids

    def call(self, inputs):

        input_shape = K.shape(inputs)
        batch_size, seq_len = input_shape[0], input_shape[1]

        if self.custom_position_ids:
            inputs, position_ids = inputs
        else:

            position_ids = K.arange(0, seq_len, dtype=K.floatx())[None]

        indices = K.arange(0, self.output_dim // 2, dtype=K.floatx())

        indices = K.pow(10000.0, -2 * indices / self.output_dim)


        pos_embeddings = tf.einsum('bn,d->bnd', position_ids, indices)
        pos_embeddings = K.concatenate([
            K.sin(pos_embeddings)[..., None],
            K.cos(pos_embeddings)[..., None]
        ])
        pos_embeddings = K.reshape(
            pos_embeddings, (-1, seq_len, self.output_dim)
        )

        if self.merge_mode == 'add':
            return inputs + pos_embeddings
        elif self.merge_mode == 'mul':
            return inputs * pos_embeddings
        else:
            if not self.custom_position_ids:
                pos_embeddings = K.tile(pos_embeddings, [batch_size, 1, 1])
            return K.concatenate([inputs, pos_embeddings])

    def compute_output_shape(self, input_shape):
        if self.custom_position_ids:
            input_shape = input_shape[0]

        if self.merge_mode in ['add', 'mul']:
            return input_shape
        else:
            return input_shape[:2] + (input_shape[2] + self.output_dim,)

    def get_config(self):
        config = {
            'output_dim': self.output_dim,
            'merge_mode': self.merge_mode,
            'custom_position_ids': self.custom_position_ids,
        }
        base_config = super(SinusoidalPositionEmbedding, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


class PositionEmbedding(Layer):


    def __init__(
            self,
            input_dim,
            output_dim,
            merge_mode='add',
            hierarchical=None,
            embeddings_initializer='zeros',
            custom_position_ids=False,
            **kwargs
    ):
        super(PositionEmbedding, self).__init__(**kwargs)
        self.input_dim = input_dim  
        self.output_dim = output_dim 
        self.merge_mode = merge_mode  
        self.hierarchical = hierarchical
        self.embeddings_initializer = initializers.get(embeddings_initializer)
        self.custom_position_ids = custom_position_ids

    def build(self, input_shape):
        super(PositionEmbedding, self).build(input_shape)
        self.embeddings = self.add_weight(
            name='embeddings',
            shape=(self.input_dim, self.output_dim),
            initializer=self.embeddings_initializer
        )  

    def call(self, inputs):

        input_shape = K.shape(inputs)
        batch_size, seq_len = input_shape[0], input_shape[1]

        if self.custom_position_ids:
            inputs, position_ids = inputs
            if K.dtype(position_ids) != 'int32':
                position_ids = K.cast(position_ids, 'int32')
        else:

            position_ids = K.arange(0, seq_len, dtype='int32')[None]

        if self.hierarchical:
            alpha = 0.4 if self.hierarchical is True else self.hierarchical
            embeddings = self.embeddings - alpha * self.embeddings[:1]
            embeddings = embeddings / (1 - alpha)
            embeddings_x = K.gather(embeddings, position_ids // self.input_dim)
            embeddings_y = K.gather(embeddings, position_ids % self.input_dim)
            pos_embeddings = alpha * embeddings_x + (1 - alpha) * embeddings_y
        else:

            if self.custom_position_ids:
                pos_embeddings = K.gather(self.embeddings, position_ids)
            else:

                pos_embeddings = self.embeddings[None, :seq_len]

        if self.merge_mode == 'add':
            return inputs + pos_embeddings

        elif self.merge_mode == 'mul':
            return inputs * pos_embeddings
        else:
            if not self.custom_position_ids:
                pos_embeddings = K.tile(pos_embeddings, [batch_size, 1, 1])

            return K.concatenate([inputs, pos_embeddings])

    def compute_output_shape(self, input_shape):
        if self.custom_position_ids:
            input_shape = input_shape[0]

        if self.merge_mode in ['add', 'mul']:
            return input_shape
        else:
            return input_shape[:2] + (input_shape[2] + self.output_dim,)

    def get_config(self):
        config = {
            'input_dim': self.input_dim,
            'output_dim': self.output_dim,
            'merge_mode': self.merge_mode,
            'hierarchical': self.hierarchical,
            'embeddings_initializer':
                initializers.serialize(self.embeddings_initializer),
            'custom_position_ids': self.custom_position_ids,
        }
        base_config = super(PositionEmbedding, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

class MultiHeadSelfAttention(layers.Layer):
    def __init__(self, embedding_dim, num_heads, dropout=0.1):
        super(MultiHeadSelfAttention, self).__init__()
        self.embedding_dim = embedding_dim
        self.num_heads = num_heads
        self.dropout = dropout

        if embedding_dim % num_heads != 0:
            raise ValueError("embedding_dim must be divisible by num_heads")

        self.projection_dim = embedding_dim // num_heads
        self.query_dense = layers.Dense(embedding_dim)
        self.key_dense = layers.Dense(embedding_dim)
        self.value_dense = layers.Dense(embedding_dim)
        self.combine_heads = layers.Dense(embedding_dim)
        self.dropout_layer = layers.Dropout(dropout)

    def attention(self, query, key, value):
        score = tf.matmul(query, key, transpose_b=True)
        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)
        scaled_score = score / (tf.math.sqrt(dim_key) + 1)

        weights = tf.nn.softmax(scaled_score, axis=-1)
        output = tf.matmul(weights, value)
        return output, weights

    def separate_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]

        query = self.query_dense(inputs)
        key = self.key_dense(inputs)
        value = self.value_dense(inputs)

        query = self.separate_heads(query, batch_size)
        key = self.separate_heads(key, batch_size)
        value = self.separate_heads(value, batch_size)

        attention, _ = self.attention(query, key, value)
        attention = tf.transpose(attention, perm=[0, 2, 1, 3])

        concat_attention = tf.reshape(attention, (batch_size, -1, self.embedding_dim))
        output = self.combine_heads(concat_attention)
        output = self.dropout_layer(output)
        return output


class FeedForwardNetwork(layers.Layer):
    def __init__(self, embedding_dim, intermediate_dim):
        super(FeedForwardNetwork, self).__init__()
        self.dense1 = layers.Dense(intermediate_dim, activation="relu")
        self.dense2 = layers.Dense(embedding_dim)

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        return x


class ConformerEncoderBlock(layers.Layer):
    def __init__(self, embedding_dim, num_heads, feed_forward_dim, dropout=0.1):
        super(ConformerEncoderBlock, self).__init__()
        self.attention = MultiHeadSelfAttention(embedding_dim, num_heads, dropout)
        self.feed_forward_network = FeedForwardNetwork(embedding_dim, feed_forward_dim)
        self.attention_layer_norm = layers.LayerNormalization(epsilon=1e-6)
        self.feed_forward_layer_norm = layers.LayerNormalization(epsilon=1e-6)
        self.dropout = layers.Dropout(dropout)

    def call(self, inputs, training):
        attention_output = self.attention(inputs)
        attention_output = self.dropout(attention_output, training=training)
        residual = tf.add(inputs, attention_output)
        attention_output = self.attention_layer_norm(residual)

        feed_forward_output = self.feed_forward_network(attention_output)
        feed_forward_output = self.dropout(feed_forward_output, training=training)
        output = tf.add(attention_output, feed_forward_output)
        output = self.feed_forward_layer_norm(output)
        return output


class ConformerEncoder(layers.Layer):
    def __init__(self, num_blocks, embedding_dim, num_heads, feed_forward_dim, dropout=0.1):
        super(ConformerEncoder, self).__init__()
        self.embedding_dim = embedding_dim
        self.num_blocks = num_blocks
        self.encoders = [ConformerEncoderBlock(embedding_dim,
                                               num_heads,
                                               feed_forward_dim,
                                               dropout)
                         for _ in range(num_blocks)]
        self.dropout = layers.Dropout(dropout)

    def call(self, inputs, training):
        x = inputs
        for i in range(self.num_blocks):
            x = self.encoders[i](x, training)
        x = self.dropout(x, training=training)
        return x

class MyMultiHeadAttention(Layer):
    def __init__(self, output_dim, num_head, kernel_initializer='glorot_uniform', **kwargs):
        self.output_dim = output_dim
        self.num_head = num_head
        self.kernel_initializer = initializers.get(kernel_initializer)
        super(MyMultiHeadAttention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name='W',
                                 shape=(self.num_head, 3, input_shape[2], self.output_dim),
                                 initializer=self.kernel_initializer,
                                 trainable=True)
        self.Wo = self.add_weight(name='Wo',
                                  shape=(self.num_head * self.output_dim, self.output_dim),
                                  initializer=self.kernel_initializer,
                                  trainable=True)
        self.built = True

    def call(self, x):
        q = K.dot(x, self.W[0, 0])
        k = K.dot(x, self.W[0, 1])
        v = K.dot(x, self.W[0, 2])
        e = K.batch_dot(q, K.permute_dimensions(k, [0, 2, 1]))  
        e = e / (self.output_dim ** 0.5)
        e = K.softmax(e)
        outputs = K.batch_dot(e, v)
        for i in range(1, self.W.shape[0]):
            q = K.dot(x, self.W[i, 0])
            k = K.dot(x, self.W[i, 1])
            v = K.dot(x, self.W[i, 2])

            e = K.batch_dot(q, K.permute_dimensions(k, [0, 2, 1])) 
            e = e / (self.output_dim ** 0.5)
            e = K.softmax(e)
  
            o = K.batch_dot(e, v)
            outputs = K.concatenate([outputs, o])
        z = K.dot(outputs, self.Wo)
        return z

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[1], self.output_dim)

    def get_config(self):
        config = super().get_config().copy()
        config.update({
            "output_dim": self.output_dim,
            'num_head': self.num_head,
            'kernel_initializer': self.kernel_initializer
        })
        return config


class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super().__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim), ]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)
class TokenAndPositionEmbedding(layers.Layer):
    def __init__(self, maxlen, vocab_size, embed_dim):
        super().__init__()
        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        return x + positions
y_train = np.load("data/dataset/train_y.npy")
x_train_emb = np.load("data/dataset/train_emb.npy")
x_train_ast = np.load("data/dataset/train_ast.npy")
x_train_dfg = np.load("data/dataset/train_dfg.npy")
x_train_cfg = np.load("data/dataset/train_cfg.npy")

# Load validation set
y_val = np.load("data/dataset/valid_y.npy")
x_val_emb = np.load("data/dataset/valid_emb.npy")
x_val_ast = np.load("data/dataset/valid_ast.npy")
x_val_dfg = np.load("data/dataset/valid_dfg.npy")
x_val_cfg = np.load("data/dataset/valid_cfg.npy")

# Load test set

y_test = np.load("data/dataset/test_y.npy")
x_test_emb = np.load("data/dataset/test_emb.npy")
x_test_ast = np.load("data/dataset/test_ast.npy")
x_test_dfg = np.load("data/dataset/test_dfg.npy")
x_test_cfg = np.load("data/dataset/test_cfg.npy")
# Model input
input_emb = Input(shape=(1, 768))
input_dfg = Input(shape=(200, 200))
input_cfg = Input(shape=(200, 200))
input_ast = Input(shape=(200, 200))
# sine cosine encoding
sin_emb = SinusoidalPositionEmbedding(output_dim=768, merge_mode="mul")(input_emb)
sin_dfg = SinusoidalPositionEmbedding(output_dim=200, merge_mode="mul")(input_dfg)
sin_cfg = SinusoidalPositionEmbedding(output_dim=200, merge_mode="mul")(input_cfg)
sin_ast = SinusoidalPositionEmbedding(output_dim=200, merge_mode="mul")(input_ast)
shape_emb1 = Reshape((1, 768))(sin_emb)

conforencode_emb = ConformerEncoder(embedding_dim=768, num_heads=8, feed_forward_dim=1024, num_blocks=12)(shape_emb1)
conforencode_ast = ConformerEncoder(embedding_dim=200, num_heads=8, feed_forward_dim=1024, num_blocks=12)(sin_ast)
conforencode_cfg = ConformerEncoder(embedding_dim=200, num_heads=8, feed_forward_dim=1024, num_blocks=12)(sin_cfg)
conforencode_dfg = ConformerEncoder(embedding_dim=200, num_heads=8, feed_forward_dim=1024, num_blocks=12)(sin_dfg)

shape_emb2 = Reshape((1, 768))(conforencode_emb)

flatten_emb = Flatten()(shape_emb2)
flatten_ast = Flatten()(conforencode_ast)
flatten_dfg = Flatten()(conforencode_dfg)
flatten_cfg = Flatten()(conforencode_cfg)

merged = concatenate([flatten_emb, flatten_dfg, flatten_cfg, flatten_ast])

dense_1 = Dense(1024, activation="relu")(merged)
drop_1 = Dropout(0.1)(dense_1)
z = Dense(2, activation="softmax")(drop_1)

model = Model(inputs=[input_emb, input_dfg, input_cfg, input_ast], outputs=z)
model.compile(optimizer=Adam(learning_rate=1e-5), loss=["sparse_categorical_crossentropy"],  # 8e-7
              metrics=["accuracy", km.sparse_categorical_f1_score(), km.sparse_categorical_precision(),
                       km.sparse_categorical_recall()])
model.summary()
checkpoints = ModelCheckpoint(filepath='model/ck/weights.{epoch:04d}.hdf5', monitor="val_loss", verbose=1,
                              save_weights_only=True, period=1)

history = model.fit(
    [x_train_emb, x_train_dfg, x_train_cfg, x_train_ast], y_train,
    validation_data=([x_val_emb, x_val_dfg, x_val_cfg, x_val_ast], y_val),
    epochs=50, batch_size=64, verbose=2, callbacks=[checkpoints])
score = model.evaluate([x_test_emb, x_test_dfg, x_test_cfg, x_test_ast], y_test, verbose=0, batch_size=128)
print(score)
print(model.metrics_names)
